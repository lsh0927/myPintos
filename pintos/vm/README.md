## Keyword Summary

### I. Virtual Memory

> **프로세스가 실제 물리 메모리(RAM)에 직접 접근하지 않고, 운영체제가 제공하는 추상화된 주소 공간을 사용하는 메모리 관리 기법**  
> Mapping? : 프로세스는 자신만의 독립된 메모리 공간을 가지는 것처럼 보이며, OS가 이를 물리 메모리와 mapping을 진행

#### 1. Virtual Memory의 필요성

- Protection
	- 프로세스 간 메모리 침범을 방지
	- 한 프로세스가 다른 프로세스의 메모릴 접근하면 운영체제가 이를 차단
- Abstraction
	- 각 프로세스는 연속적인 큰 메모리를 독립적으로 가진 것처럼 보임
	- 실제 물리 메모리는 파편화되어 있어도 문제 없음
- 효율적 메모리 사용
	- 모든 프로그램을 동시에 메모리에 올릴 필요 없음
	- 요구 페이징(Demand Paging)으로 필요한 페이지만 메모리에 적재

#### 2. 구현 방식
- Paging
	- 가상 주소 공간을 고정 크기의 Page로 나누고, 물리 메모리를 같은 크기의 Frame으로 나눔
	- 가상 주소 → 물리 주소 변환은 **페이지 테이블**로 관리
- Segmentation
	- 코드 / 데이터 / 스택과 같은 의미 있는 단위로 나누어 관리
	- 현재는 페이징과 혼합된 방식으로 사용
- Page Fault
	- 필요한 페이지가 메모리에 없을 때 발생
	- OS가 디스크에서 해당 페이지를 로드

#### 3. PintOS와의 연관성
- 페이지 테이블 관리 시점
	- 각 프로세스마다 독립적인 페이지 테이블 존재
	- 가상 주소와 물리 주소 매핑을 관리
- Lazy Loading
	- 실행 시 전체 프로그램을 메모리에 적재하지 않음
	- 접근 시 필요한 페이지만 디스크에서 불러옴
- Page Fault 처리
	- 잘못된 접근이면 Segmentaation Fault
	- 올바른 접근인데 페이지가 없는 경우 디스크에서 로드
- SWAP
	- 물리 메모리가 부족할 때 일부 페이지를 디스크로 내본내고 필요 시 다시 가져옴

### II. Page Table

> **가상주소와 물리주소를 매핑하기 위한 자료구조**  
> CPU는 프로그램이 사용하는 가상 주소를 직접 물리주소로 변환하지 못하기에, OS가 관리하는 페이지 테이블을 통해 변환 수행

#### 1. 동작 원리
- Page Number / Page Offset
	- Page Number : 페이지 테이블 인덱스로 사용
	- Page Offset : 페이지 내부에서의 위치
- CPU는 Memory Management Unit(MMU)를 통해 변환을 수행
	- 가상 페이지 번호 → 페이지 테이블 참조 → 물리 프레임 번호(PFN)으로 변환
	- 최종 주소 = PFN + Offset

#### 2. 주요 엔트리 = PTE, Page Table Entry
- Present bit: 페이지가 메모리에 존재하는지 여부
- Frame number: 물리 메모리 프레임의 시작 주소
- Protection bits: 읽기 / 쓰기 / 실행 권한
- Dirty bit: 페이지가 수정되었는지 여부
- Accessed bit: 최근에 참조된 여부

#### 3. 구조
- 단일 레벨 페이지 테이블 : Single Level Page Table
	- 단순히 배열 형태
	- 주소 공간이 작을 때 사용
- 다단계 페이지 테이블 : Multi Level Page Table
	- 메모리 낭비를 줄이기 위해 트리 구조 사용
	- x86-32 : 2단계 페이지 테이블 = Page Directory + Page Table
	- x86-64 : 최대 4단계 = Page Map Level 4 → Page Directory Pointer Table → Page Directory → Page Table
- TLB : Translation Lookaside Buffer
	- 페이지 테이블 접근 속도를 높이기 위해, CPU 내부에 최근 주소 변환 결과를 캐싱

#### 4. PintOS와의 연관성
- 가상 주소와 물리 주소 매핑 관리
	- 각 프로세스는 독립적인 페이지 테이블을 가짐
- Lazy Loading
	- 실행 파일을 실행할 때 모든 페이지를 한 번에 로드하지 않고, 접근할 때 페이지 폴트 발생 시 로드
- 스왑(Swap) 지원
	- 물리 메모리가 부족하면 페이지를 디스크로 내보내고, 필요할 때 다시 불러오기
- 보호 기법
	- 잘못된 접근은 페이지 폴트 → 프로세스 종료 (세그멘테이션 폴트와 유사)

### III. Translation Lookaside Buffer, TLB

> **최근 사용된 주소 → 물리 주소 변환 정보를 저장하는 캐시**  
> CPU 내부의 Memory Management Unit(MMU)에 존재, 페이지 테이블 접근 속도를 줄이기 위한 특수 캐시

#### 1. 필요한 이유
- 가상 메모리에서는 가상 주소 → 페이지 테이블 → 물리 주소 변환이 필요
- 다단계 페이지 테이블 구조에서는 변환 시 메모리 접근이 발생
- 변환 결과를 TLB에 저장, 메모리 접근 시간을 획기적으로 줄임

#### 2. 동작 원리
- CPU가 가상 주소를 생성
- MMU가 해당 가상 페이지 번호를 TLB에서 검색
	- TLB Hit : 변환 정보가 있으면 즉시 물리 주소 반환
	- TLB Miss : 변환 정보가 없으면 페이지 테이블을 참조하여 변환, 그리고 결과를 TLB에 저장
- 변환된 물리 주소를 사용해서 실제 메모리에 접근

#### 3. 특징
- 작고 빠른 캐시 : 일반적으로 수십 ~ 수백 개의 엔트리
- Associativity : Direct-mapped, Set-associative, Fully-associative 구조 사용
- TLB Miss Handling
	- 하드웨어가 직접 처리 : x86
	- OS가 처리 : MIPS 등
- Context Switch 문제
	- OS는 직접 TLB에 접근하지 못하고, 페이지 테이블을 관리하는 방식으로 간점적으로 영향
	- TLB Miss가 많아지면 성능 저하 발생 → TLB Locality 최적화가 중요
	- 현대 CPU는 Instruction TLB(ITLB)와 Data TLB(DTLB)를 분리하여 성능을 향상

#### 4. PintOS와의 연관성
- PintOS는 x86 32비트 환경에서 동작하는데, CPU의 하드웨어 TLB를 직접 다루지 않음
- 하지만 페이지 폴트(Page Fault) 처리 시, TLB 갱신이 암묵적으로 발생
	- CPU가 TLB miss → 페이지 테이블 참조 → 잘못된 접근 시 페이지 폴트 발생
	- PintOS에서 페이지 폴트 핸들러를 구현하면, 올바른 페이지 매핑을 생성하고, 이후 CPU가 이를 TLB에 반영
- 즉, PintOS에서는 TLB를 직접 제어하지 않고, 페이지 테이블 관리와 페이지 폴트 처리로 간접적으로 TLB 동작을 경험할 수 있음

### IV. Page Fault

> **프로세스가 접근하려는 가상 페이지가 물리 메모리에 존재하지 않을 때 발생하는 예외**  
> CPU가 TLB와 페이지 테이블을 확인했지만, 해당 페이지가 메모리에 없는 경우 운영체제가 개입하여 처리

#### 1. 발생 과정
- 프로세스가 특정 가상 주소를 참조
- MMU가 TLB에서 변환 시도 → 실패하면 페이지 테이블 조회
- 페이지 테이블에 `Present bit = 0`이면, 물리 메모리에 해당 페이지 없음
- CPU가 Page Fault 예외를 발생시켜 커널 모드로 전환
- OS의 Page Fault Handler가 실행

#### 2. 종류
- Valid but not in memory (Demand Paging)
	- 접근 가능한 합법적 주소지만, 아직 메모리에 적재되지 않음
	- 운영체제가 디스크에서 해당 페이지를 메모리에 로드
- Invalid access (Segmentation Fault)
	- 접근 권한이 없거나, 잘못된 주소 접근
	- NULL 포인터 역참조, 읽기 전용 페이지에 쓰기 → 프로세스 강제 종료

#### 3. 처리 과정 (합법적 접근인 경우)
- CPU가 Page Fault 발생 → 커널로 제어 전환
- OS가 페이지 테이블을 확인하여 해당 페이지가 어디에 있는지(디스크, 스왑) 탐ㅁ색
- 빈 물리 프레임을 할당
	- 메모리가 부족하면 페이지 교체 알고리즘(LRU etc.)을 사용해 기존 페이지를 스왑 아웃
- 디스크에서 해당 페이지를 메모리에 업로드
- 페이지 테이블 갱신, TLB 갱신
- 예외가 발생한 명령어를 다시 실행 → 정상 동작 재개

#### 4. 성능
- 비용이 매우 큼 : 메모리 접근(nano sec.) vs 디스크 접근(micro ~ mili sec.)
- OS는 Locality원리를 활용하여 Page Fault를 최소화

#### 5. PintOS와 연관성
- Lazy Loading
	- 프로그램 실행 시 전체를 메모리에 적재하지 않고, 접근할 때 Page Fault 발생 → 그때 디스크에서 로드
- Stack Growth
	- 스택이 확장되는 경우, Page Fault 발생 시 새로운 페이지 할당
- 잘못된 접근 처리
	- 유효하지 않은 주소 접근이면 프로세스를 종료 (세그멘테이션 폴트 처리)
- Swap
	- 메모리가 부족할 때 일부 페이지를 디스크로 내보내고, Page Fault 발생 시 다시 가져오기

### V. Lazy Loading

> **프로그램 실행 시 필요한 모든 데이터를 한 번에 메모리에 올리지 않고, 실제로 접근할 때 (on-demand) 해당 페이지를 메모리에 적재하는 기법**  
> 필요할 때까지 기다렸다가 로드하는 방식으로, Demand Paging의 대표적인 구현

#### 1. 사용 이유
- 성능 최적화
	- 실행 파일 전체를 메모리에 로드하는 것은 불필요한 오버헤드
	- 실제로는 많은 코드나 데이터가 실행되지 않음
- 메모리 절약
	- 필요한 부분만 메모리에 적재하므로, RAM 사용량 감소
- 빠른 실행 시작
	- 프로그램 시작 시 전체를 로드하지 않으므로 실행 속도가 빨라짐

#### 2. 동작 과정
- 프로그램 실행 → 운영체제는 전체 코드 / 데이터를 메모리에 올리지 않음
- 특정 코드 / 데이터에 접근 시도
- 해당 페이지가 물리 메모리에 없음 → Page Fault가 발생
- 운영체제의 Page Fault Handler가 실행
	- 접근이 유효하면, 디스크(실행 파일 or 스왑 공간)에서 해당 페이지 로드
	- 페이지 테이블과 TLB 갱신
- CPU가 중단된 명령어를 다시 실행 → 정상 실행 재개

#### 3. 장점과 단점
- 장점
	- 메모리 사용 최적화
	- 실행 시작 속도 향상
	- 불필요한 코드 / 데이터 로드를 피할 수 있음
- 단점
	- 처음 접근 시 Page Fault가 발생하여 지연 생김
	- Page Fault가 잦으면 성능 저하 발생

#### 4. PintOS와 연관성
- 프로그램 실행 시 전체 실행 파일을 메모리에 올리지 않고, 보조 저장장치(디스크)의 정보를 페이지 단위로 관리
- 프로세스가 특정 주소(코드 / 데이터 / 스택)를 참조할 때 Page Fault 발생
- Page Fault Handler가 해당 페이지를 디스크에서 읽어와 물리 메모리에 적재
- 잘못된 접근이면 프로세스를 종료(segmentation fault)
- 이 과정을 통해 PintOS는 Demand Paging 기반의 Lazy Loading을 실습적으로 구현

### VI. Page Replacement Policy

> **물리 메모리가 가득 찼을 때, 새로운 페이지를 적재하기 위해 어떤 페이지를 내보낼지(Swap Out) 결정하는 알고리즘**  
> Page Fault 횟수를 최소화하여 시스템 성능을 높이는 것

#### 1. 필요성
- 가상 메모리는 실행 중인 프로그램이 실제 물리 메모리보다 큰 주소 공간을 사용할 수 있게 해줌
- 하지만 물리 메모리는 제한적 → 새로운 페이지를 적재해야 하는데 빈 공간이 없으면 기존 페이지를 교체
- 이때 OS가 Page Replacement Policy를 사용

#### 2. 대표적인 Page Replacement Policy
- Optimal
	- 앞으로 가장 오랫동안 사용되지 않을 페이지를 교체
	- 이론적으로 최소의 Page Fault 발생
	- 단점 : 미래 참조를 알 수 없으므로 실제 구현 불가 → 성능 평가의 기준으로만 사용
- FIFO
	- 메모리에 가장 오래 있었던 페이지를 교체
	- 단순하지만 성능이 떨어질 수 있음
- LRU
	- 가장 오랫동안 사용되지 않은 페이지를 교체
	- Localit 원리를 잘 반영하여 실제 시스템에서 많이 사용
	- 구현 시 하드웨어 지원 필요
- LFU
	- 참조 횟수가 가장 적은 페이지를 교체
	- 단점 : 최근에 집중적으로 사용된 페이지라도 과거 기록 때문에 희생될 수 있음
- Clock
	- FIFO를 보완한 알고리즘
	- 참조 비트를 확인해 0이면 교체, 1이면 기회를 주고 0으로 바꿈
	- 구현이 효율적이어서 실제 OS에서 자주 사용됨

#### 3. PintOS와 연관성
- 물리 메모리가 부족하면 스왑 공간(Swap Space)으로 일부 페이지를 내보냄
- 어떤 페이지를 내보낼지 결정하는 정책을 구현
- 보통 Clock 알고리즘을 구현하여 효율적인 교체를 지원
- 이후 해당 페이지에 다시 접근하면 Page Fault 발생 → 디스크에서 다시 불러옴

### VII. Anonymous Page

> **특정 파일에 매핑되지 않은 가상 메모리 페이지를 의미**  
> 보통 프로세스의 힙, 스택, 전역변수의 BSS 영역처럼 실행 파일이나 디스크의 특정 파일에 직접 연결되지 않은 메모리 영역  
> 즉, 어느 파일에도 소속되지 않은 페이지이므로 익명으로 부름

#### 1. 특징
- 파일 매핑 없음
	- 실행 파일 코드나 데이터 세그먼트는 파일 매핑이 존재하지만, Anonymous Page는 그렇지 않음
- 초기화 방식
	- BSS 영역(.bss)은 0으로 초기화된 Anonymous Page
	- 힙 / 스택은 malloc / new, 함수 호출 등으로 필요할 때 Anonymous Page를 추가 생성
- 스왑 가능
	- Anonymous Page는 파일과 연결되지 않았기 때문에, 메모리가 부족할 경우 디스크의 스왑 영역(swap space)에 저장

#### 2. 동작 과정
- 프로세스가 힙/스택에서 새로운 메모리를 요청
- 운영체제가 Anonymous Page를 할당 (가상 주소 공간에 매핑)
- 초기에는 물리 메모리와 매핑되지 않고, 접근 시 Page Fault 발생
- 운영체제가 물리 메모리를 할당하고, 필요하면 swap 영역을 이용해 저장 / 복구

#### 3. Anonymous Page vs File-Backed Page
|구분|Anonymous Page|File-Backed Page|
|---|--------------|----------------|
|연결|특정 파일과 연결 없음|실행 파일, mmap 등 특정 파일과 연결|
|예시|힙, 스택, BSS|코드 영역, 데이터 영역, mmap된 파일|
|스왑|스왑 영역에 저장|파일에서 다시 읽어옴|
|초기화|0으로 초기화(BSS), 동적 할당|파일 내용으로 초기화|

#### 4. PintOS와 연관성
- Anon Page 구현
	- 스택 확장(Stack Growth) 시 새로운 페이지를 Anonymous Page로 생성
	- malloc / new 같은 동적 메모리 할당을 처리할 때도 사용
- Swap 지원
	- Anonymous Page는 파일 매핑이 없으므로, 메모리 부족 시 스왑 영역에 저장
	- 다시 접근하면 swap에서 불러와 복구
- File-backed Page와 구분 필요
	- 실행 파일 로딩 시에는 File-backed Page 사용
	- 실행 중 동적 생성된 메모리는 Anonymous Page 사용

### VIII. Swap Disk

> **RAM이 부족할 때, 메모리 페이지를 임시로 저장하는 보조 저장장치 영역**  
> OS는 자주 사용하지 않는 페이지를 스왑 디스크에 내보내고, 다시 필요할 때 메모리로 가져와 사용  
> 이를 통해 물리 메모리보다 큰 프로그램 실행이 가능

#### 1. 필요성
- 메모리 부족 문제 해결
	- 모든 프로세스를 동시에 메모리에 적재할 수 없음 → 일부 페이지를 디스크로 이동
- 가상 메모리 구현
	- 실제 메모리 크기보다 큰 가상 주소 공간 지원
- 메모리 보호 및 효율적 활용
	- 덜 자주 사용하는 페이지는 스왑으로 내보내고, 자주 쓰이는 페이지에 메모리를 집중

#### 2. 동작 과정
- 프로세스가 페이지를 필요로 할 때, 해당 페이지가 메모리에 없으면 Page Fault 발생
- OS는 빈 프레임이 없으면, Page Replacement Policy에 따라 희생 페이지를 선택
- 희생 페이지가 Anonymous Page이면 스왑 디스크에 저장
	- File-Backed Page라면 디스크의 원본 파일로부터 다시 읽어올 수 있으므로 스왑 필요 없음
- 새로 필요한 페이지를 메모리에 적재
- 나중에 해당 페이지가 다시 필요하면 스왑 디스크에서 불러옴

#### 3. 특징
- 속도 : RAM보다 훨씬 느림 (마이크로초 vs 밀리초 단위)
- 단위 : 보통 페이지 단위(4KB)로 저장 / 복구
- 구조 : 디스크의 특정 파티션이나 파일을 스왑 영역으로 사용
- 효율성 문제 : 스왑 남용 시 시스템 속도 저하

#### 4. PintOS와 연관성
- Swap Table 관리
	- 스왑 공간을 페이지 단위로 관리하기 위한 자료구조 필요
	- 어떤 페이지가 어떤 스왑 슬롯에 저장되었는지 기록
- Anonymous Page와 연계
	- 파일과 연결되지 않은 Anonymous Page만 스왑 디스크에 저장
	- File-Backed Page는 원본 파일에서 다시 로드 가능하므로 스왑하지 않음
- 교체 정책 적용
	- 메모리가 부족하면 Page Replacement Policy(FIFO, Clock 등)을 통해 교체할 페이지 선택 후 스왑 아웃
- Page Fault 처리
	- 스왑에 저장된 페이지에 접근하면 Page Fault 발생 → 스왑 디스크에서 읽어와 메모리에 복구

### IX. File-Backed Page

> **디스크의 특정 파일과 연결되어 있는 메모리 페이지를 의미**  
> 메모리 페이지의 내용이 디스크의 실행 파일, 라이브러리, `mmap()`으로 매핑된 파일에 의해 뒷받침(backed)되는 구조  
> 필요한 경우 페이지의 내용은 해당 파일로부터 다시 읽어올 수 있음

#### 1. 특징
- 파일과 매핑
	- 실행 파일의 코드 영역(Text Segment)
	- 초기화된 전역 변수(Data Segment)
	- `mmap()` 시스템 콜을 통해 매핑된 데이터
- 재구성 가능
	- 메모리에서 제거되어도 원본 파일에서 다시 읽어올 수 있음
	- 따라서 스왑 디스크에 저장할 필요 없음
- 공유 가능
	- 같은 파일을 여러 프로세스가 매핑하면, 동일한 물리 프레임을 공유 가능

#### 2. File-Backed Page vs Anonymous Page
|구분|File-Backed Page|Anonymous Page|
|---|----------------|--------------|
|연결 대상|실행 파일, 라이브러리, mmap 파일|힙, 스택, BSS|
|재구성|파일에서 다시 읽어오기 가능|swap 공간에 저장 필요|
|스왑 필요성|없음(원본 파일 존재)|있음(파일과 연결되지 않음)|
|공유 가능성|여러 프로세스가 공유 가능|프로세스별 독립적|

#### 3. File-Backed Page의 동작 과정
- 프로그램 실행 시 코드 / 데이터 전체를 적재하지 않고, Lazy Loading을 통해 접근할 때 Page Fault 발생
- OS가 실행 파일의 해당 부분을 디스크에서 읽어와 메모리에 적재
- 해당 페이지는 File-Backed Page로 관리
- 필요 없어지면 메모리에서 제거 가능, 다시 필요하면 원본 파일에서 다시 읽어옴

#### 4. PintOS와 연관성
- 프로그램 로딩
	- 실행 파일의 코드와 데이터 세그먼트는 File-Backed Page로 매핑
- mmap 시스템 콜
	- 사용자 프로세스가 파일을 메모리에 매핑할 때 File-Backed Page 생성
- Page Replacement
	- File-Backed Page는 스왑 디스크 대신 원본 파일에서 다시 읽어오기 때문에, 스왑 공간을 사용하지 않음
- Page Fault 처리
	- 접근 시 Lazy-Loading → 파일에서 페이지 읽어옴
	- 쓰기 발생 시 Dirty Bit 체크 후, 필요하다면 파일에 반영

### X. Direct Memory Access

> **CPU의 개입 없이 I/O 장치가 메모리와 직접 데이터 전송을 수행하는 방식**  
> 전통적인 I/O는 CPU가 데이터를 하나씩 주고 받았지만, DMA는 전송 시작 / 종료 제어만 CPU가 담당하고 실제 데이터 이동은 DMA 컨트롤러가 수행

#### 1. 필요한 이유
- CPU 부하 감소
	- CPU가 모든 I/O 전송을 직접 수행하면 성능 저하
	- DMA는 데이터 전송을 하드웨어가 맡으므로 CPU는 다른 연산 수행 가능
- I/O 속도 향상
	- 블록 단위 전송 가능 → 효율적
- 병렬성 확보
	- CPU와 I/O 동작을 동시에 수행 가능

#### 2. 동작 과정
- CPU가 DMA 컨트롤러에 명령어 전달
	- 전송할 메모리 주소, I/O 장치 주소, 전송 크기
- DMA 컨트롤러가 데이터 전송 시작
	- CPU 개입 없이 메모리 ↔ 장치 간 직접 전송 수행
- 전송 완료 시 인터럽트 발생
	- DMA 컨트롤러가 CPU에 완료 알림
	- CPU는 이후 필요한 후처리 수행

#### 3. 특징
- Block Transfer 방식 : 한번 설정으로 대량 데이터 전송 가능
- 인터럽트 기반 완료 알림 : 전송이 끝난 시점에 CPU 개입
- 메모리 보호 필요 : DMA도 메모리에 직접 접근하므로, OS가 허용된 영역만 접근하도록 제어

#### 4. PintOS와 연관성
- 직접 구현은 없음
- 하지만, 디스크 I/O 시 인터럽트 기반 처리를 경험할 수 있음
- 실제 OS는 블록 디바이스 드라이버에서 DMA를 적극적으로 사용하여 CPU 부하를 줄임
